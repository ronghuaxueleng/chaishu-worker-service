#!/usr/bin/env python3
"""
çŸ¥è¯†å›¾è°± Worker ç‹¬ç«‹èŠ‚ç‚¹å¯åŠ¨è„šæœ¬
ç”¨äºåœ¨å¤šå°æœåŠ¡å™¨ä¸Šåˆ†å¸ƒå¼è¿è¡Œ Worker

ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®ï¼š
- KG_WORKER_NODE_NAME: èŠ‚ç‚¹åç§°ï¼ˆç”¨äºæ ‡è¯†ï¼‰
- KG_WORKERS_PER_PROVIDER: æ¯ä¸ª Provider å¯åŠ¨çš„è¿›ç¨‹æ•°ï¼ˆé»˜è®¤2ï¼‰
- KG_WORKER_PROVIDERS: æŒ‡å®š Providersï¼ˆé€—å·åˆ†éš”ï¼Œå¯é€‰ï¼‰
- KG_WORKER_GUARD_INTERVAL: å®ˆæŠ¤çº¿ç¨‹æ£€æŸ¥é—´éš”ç§’æ•°ï¼ˆé»˜è®¤30ï¼‰
- KG_MAX_TOTAL_PROCESSES: æœ€å¤§æ€»è¿›ç¨‹æ•°ï¼ˆé»˜è®¤50ï¼‰
- KG_MAX_PROCESSES_PER_PROVIDER: å•Provideræœ€å¤§è¿›ç¨‹æ•°ï¼ˆé»˜è®¤10ï¼‰
- REDIS_HOST, DB_HOST, NEO4J_URI: å…±äº«æœåŠ¡é…ç½®

ç‰¹æ€§ï¼š
- âœ… è‡ªåŠ¨å‘ç°æ¿€æ´»çš„ AI æœåŠ¡å•†
- âœ… å®ˆæŠ¤çº¿ç¨‹è‡ªåŠ¨ä¸ºæ–°å¢çš„ AI æœåŠ¡å•†å¯åŠ¨ Worker
- âœ… å®šæœŸå¿ƒè·³æ³¨å†Œï¼Œä¸»èŠ‚ç‚¹å¯ç›‘æ§å­èŠ‚ç‚¹çŠ¶æ€
"""
import os
import sys
import time
import logging
import signal
from pathlib import Path

# æ·»åŠ çˆ¶ç›®å½•åˆ° Python è·¯å¾„ï¼ˆä»¥ä¾¿å¯¼å…¥ src æ¨¡å—ï¼‰
parent_dir = Path(__file__).parent.parent.resolve()
if str(parent_dir) not in sys.path:
    sys.path.insert(0, str(parent_dir))
    print(f"âœ“ å·²æ·»åŠ çˆ¶ç›®å½•åˆ° Python è·¯å¾„: {parent_dir}")

# åŠ è½½ .env æ–‡ä»¶
try:
    from dotenv import load_dotenv
    env_file = Path(__file__).parent / '.env'
    if env_file.exists():
        load_dotenv(env_file)
        print(f"âœ“ å·²åŠ è½½é…ç½®æ–‡ä»¶: {env_file}")
    else:
        print("âš  æœªæ‰¾åˆ° .env æ–‡ä»¶ï¼Œå°†ä½¿ç”¨ç¯å¢ƒå˜é‡")
except ImportError:
    print("âš  python-dotenv æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç¯å¢ƒå˜é‡")
except Exception as e:
    print(f"âš  åŠ è½½ .env æ–‡ä»¶å¤±è´¥: {e}")

# é…ç½®æ—¥å¿—
log_level = os.environ.get('LOG_LEVEL', 'INFO').upper()
handlers = [logging.StreamHandler()]

# å°è¯•æ·»åŠ æ–‡ä»¶æ—¥å¿—ï¼ˆå¯é€‰ï¼‰
try:
    log_dir = Path(__file__).parent / 'logs'
    log_dir.mkdir(exist_ok=True)
    handlers.append(logging.FileHandler(log_dir / 'worker.log'))
except Exception as e:
    print(f"âš  æ— æ³•åˆ›å»ºæ—¥å¿—æ–‡ä»¶: {e}ï¼Œå°†ä»…ä½¿ç”¨æ§åˆ¶å°è¾“å‡º")

logging.basicConfig(
    level=getattr(logging, log_level, logging.INFO),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=handlers
)
logger = logging.getLogger(__name__)

# ä¼˜é›…åœæ­¢æ ‡å¿—
_shutdown_requested = False


def signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å™¨ï¼šä¼˜é›…åœæ­¢"""
    global _shutdown_requested
    logger.info(f"æ”¶åˆ°ä¿¡å· {signum}ï¼Œå‡†å¤‡åœæ­¢ Worker èŠ‚ç‚¹...")
    _shutdown_requested = True


def print_banner():
    """æ‰“å°å¯åŠ¨æ¨ªå¹…"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                               â•‘
â•‘        æ‹†ä¹¦ç³»ç»Ÿ - çŸ¥è¯†å›¾è°± Worker ç‹¬ç«‹èŠ‚ç‚¹                    â•‘
â•‘        Chaishu Knowledge Graph Worker Node                    â•‘
â•‘                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    print(banner)


def validate_environment():
    """éªŒè¯å¿…è¦çš„ç¯å¢ƒå˜é‡"""
    required_vars = ['REDIS_HOST', 'DB_HOST', 'NEO4J_URI']
    missing_vars = []

    for var in required_vars:
        if not os.environ.get(var):
            missing_vars.append(var)

    if missing_vars:
        logger.error(f"ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
        logger.error("è¯·åœ¨ .env æ–‡ä»¶æˆ–ç¯å¢ƒä¸­é…ç½®è¿™äº›å˜é‡")
        return False

    return True


def main():
    """Worker èŠ‚ç‚¹ä¸»å‡½æ•°"""
    # è®¾ç½® multiprocessing å¯åŠ¨æ–¹æ³•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ç³»ç»Ÿé»˜è®¤ï¼‰
    import multiprocessing
    start_method = os.environ.get('MULTIPROCESSING_START_METHOD', '').lower()
    if start_method in ('fork', 'spawn', 'forkserver'):
        try:
            multiprocessing.set_start_method(start_method, force=True)
            print(f">>> [DEBUG] è®¾ç½® multiprocessing start method: {start_method}")
            sys.stdout.flush()
        except RuntimeError:
            print(f">>> [DEBUG] multiprocessing start method å·²è®¾ç½®ä¸º: {multiprocessing.get_start_method()}")
            sys.stdout.flush()
    else:
        current_method = multiprocessing.get_start_method()
        print(f">>> [DEBUG] ä½¿ç”¨ç³»ç»Ÿé»˜è®¤ multiprocessing start method: {current_method}")
        sys.stdout.flush()

    # æ‰“å°æ¨ªå¹…
    print_banner()

    print(">>> [DEBUG] å¼€å§‹åˆå§‹åŒ– Worker èŠ‚ç‚¹...")
    sys.stdout.flush()

    # æ³¨å†Œä¿¡å·å¤„ç†
    try:
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        print(">>> [DEBUG] ä¿¡å·å¤„ç†å™¨æ³¨å†ŒæˆåŠŸ")
        sys.stdout.flush()
    except Exception as e:
        print(f">>> [DEBUG] ä¿¡å·å¤„ç†å™¨æ³¨å†Œå¤±è´¥ï¼ˆKaggleç¯å¢ƒå¯èƒ½ä¸æ”¯æŒï¼‰: {e}")
        sys.stdout.flush()

    # è·å–é…ç½®
    node_name = os.environ.get('KG_WORKER_NODE_NAME', 'worker-node')
    per_provider = int(os.environ.get('KG_WORKERS_PER_PROVIDER', '2'))
    providers = os.environ.get('KG_WORKER_PROVIDERS', None)
    max_total = os.environ.get('KG_MAX_TOTAL_PROCESSES', '50')
    max_per_provider = os.environ.get('KG_MAX_PROCESSES_PER_PROVIDER', '10')

    if providers:
        providers = [p.strip() for p in providers.split(',') if p.strip()]

    print(">>> [DEBUG] é…ç½®è¯»å–å®Œæˆï¼Œå‡†å¤‡è¾“å‡ºé…ç½®ä¿¡æ¯...")
    sys.stdout.flush()

    logger.info("=" * 60)
    logger.info("çŸ¥è¯†å›¾è°± Worker èŠ‚ç‚¹å¯åŠ¨")
    logger.info(f"èŠ‚ç‚¹åç§°: {node_name}")
    logger.info(f"æ¯Providerè¿›ç¨‹æ•°: {per_provider}")
    logger.info(f"æœ€å¤§æ€»è¿›ç¨‹æ•°: {max_total}")
    logger.info(f"å•Provideræœ€å¤§è¿›ç¨‹æ•°: {max_per_provider}")

    if providers:
        logger.info(f"æŒ‡å®šProviders: {providers}")
    else:
        logger.info("è‡ªåŠ¨å‘ç°æ¿€æ´»çš„ Providers")

    logger.info(f"Redis: {os.environ.get('REDIS_HOST')}")
    logger.info(f"MySQL: {os.environ.get('DB_HOST')}")
    logger.info(f"Neo4j: {os.environ.get('NEO4J_URI')}")
    logger.info("=" * 60)

    print(">>> [DEBUG] é…ç½®ä¿¡æ¯è¾“å‡ºå®Œæˆ")
    sys.stdout.flush()

    # éªŒè¯ç¯å¢ƒå˜é‡
    print(">>> [DEBUG] å¼€å§‹éªŒè¯ç¯å¢ƒå˜é‡...")
    sys.stdout.flush()

    if not validate_environment():
        logger.error("ç¯å¢ƒéªŒè¯å¤±è´¥ï¼Œé€€å‡º")
        sys.exit(1)

    print(">>> [DEBUG] ç¯å¢ƒå˜é‡éªŒè¯é€šè¿‡")
    sys.stdout.flush()

    # å¯¼å…¥ Worker æ¨¡å—
    print(">>> [DEBUG] å¼€å§‹å¯¼å…¥ Worker æ¨¡å—...")
    sys.stdout.flush()

    try:
        from src.services.kg_task_worker import start_kg_task_workers, stop_all_workers, start_auto_worker_guard
        logger.info("âœ“ Worker æ¨¡å—å¯¼å…¥æˆåŠŸ")
        print(">>> [DEBUG] Worker æ¨¡å—å¯¼å…¥æˆåŠŸ")
        sys.stdout.flush()
    except Exception as e:
        logger.error(f"âœ— Worker æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        print(f">>> [DEBUG] Worker æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        sys.stdout.flush()
        import traceback
        traceback.print_exc()
        sys.exit(1)

    # å¯åŠ¨ Worker è¿›ç¨‹
    print(">>> [DEBUG] å‡†å¤‡å¯åŠ¨ Worker è¿›ç¨‹...")
    sys.stdout.flush()

    try:
        logger.info("æ­£åœ¨å¯åŠ¨ Worker è¿›ç¨‹...")
        start_kg_task_workers(
            providers=providers,
            per_provider_processes=per_provider
        )
        logger.info("âœ“ Worker è¿›ç¨‹å·²å¯åŠ¨ï¼ŒèŠ‚ç‚¹è¿›å…¥è¿è¡ŒçŠ¶æ€")
        print(">>> [DEBUG] Worker è¿›ç¨‹å·²å¯åŠ¨")
        sys.stdout.flush()
    except Exception as e:
        logger.error(f"âœ— Worker å¯åŠ¨å¤±è´¥: {e}", exc_info=True)
        print(f">>> [DEBUG] Worker å¯åŠ¨å¤±è´¥: {e}")
        sys.stdout.flush()
        import traceback
        traceback.print_exc()
        sys.exit(1)

    # æ˜¾ç¤ºæ´»è·ƒè¿›ç¨‹ä¿¡æ¯
    print(">>> [DEBUG] è·å–è¿›ç¨‹ç»Ÿè®¡...")
    sys.stdout.flush()

    try:
        from src.services.kg_task_worker import get_worker_stats
        stats = get_worker_stats()
        logger.info(f"æ´»è·ƒè¿›ç¨‹ç»Ÿè®¡: {stats}")

        print(f"\n{'=' * 60}")
        print("âœ“ Worker èŠ‚ç‚¹å¯åŠ¨æˆåŠŸï¼")
        print(f"{'=' * 60}")

        if stats.get('providers'):
            print(f"\nğŸ“Š è¿›ç¨‹ç»Ÿè®¡:")
            for provider, info in stats['providers'].items():
                print(f"  â€¢ {provider}: {info.get('alive', 0)} ä¸ªæ´»è·ƒè¿›ç¨‹")
                print(f"    - é˜Ÿåˆ—é•¿åº¦: {info.get('queue_length', 0)}")
                if info.get('pids'):
                    print(f"    - PID: {', '.join(map(str, info['pids']))}")
        else:
            print("\nâš  è­¦å‘Š: æœªæ£€æµ‹åˆ°æ´»è·ƒçš„ Worker è¿›ç¨‹")

        print(f"\n{'=' * 60}\n")
        sys.stdout.flush()
    except Exception as e:
        logger.warning(f"è·å–è¿›ç¨‹ç»Ÿè®¡å¤±è´¥: {e}")
        print(f">>> [DEBUG] è·å–è¿›ç¨‹ç»Ÿè®¡å¤±è´¥: {e}")
        sys.stdout.flush()

    # å¯åŠ¨å®ˆæŠ¤çº¿ç¨‹ï¼Œè‡ªåŠ¨ä¸ºæ–°å¢çš„ AI æœåŠ¡å•†å¯åŠ¨ Worker
    print(">>> [DEBUG] å¯åŠ¨ Worker å®ˆæŠ¤çº¿ç¨‹...")
    sys.stdout.flush()

    try:
        # è·å–å®ˆæŠ¤çº¿ç¨‹é—´éš”é…ç½®ï¼ˆé»˜è®¤30ç§’ï¼‰
        guard_interval = int(os.environ.get('KG_WORKER_GUARD_INTERVAL', '30'))
        start_auto_worker_guard(interval_seconds=guard_interval)
        logger.info(f"âœ“ Worker å®ˆæŠ¤çº¿ç¨‹å·²å¯åŠ¨ï¼Œæ£€æŸ¥é—´éš”: {guard_interval}ç§’")
        print(f">>> [DEBUG] Worker å®ˆæŠ¤çº¿ç¨‹å·²å¯åŠ¨ï¼Œæ£€æŸ¥é—´éš”: {guard_interval}ç§’")
        sys.stdout.flush()
    except Exception as e:
        logger.warning(f"âš  å®ˆæŠ¤çº¿ç¨‹å¯åŠ¨å¤±è´¥: {e}")
        print(f">>> [WARNING] å®ˆæŠ¤çº¿ç¨‹å¯åŠ¨å¤±è´¥: {e}ï¼Œå°†æ— æ³•è‡ªåŠ¨ä¸ºæ–°å¢çš„ AI æœåŠ¡å•†å¯åŠ¨ Worker")
        sys.stdout.flush()

    # å¯åŠ¨å¿ƒè·³æ³¨å†Œ
    print(">>> [DEBUG] æ³¨å†ŒèŠ‚ç‚¹å¿ƒè·³...")
    sys.stdout.flush()
    from datetime import datetime
    started_at = datetime.now().isoformat()

    def register_heartbeat():
        """æ³¨å†ŒèŠ‚ç‚¹å¿ƒè·³åˆ° Redis"""
        try:
            print(">>> [DEBUG] æ­£åœ¨è¿æ¥ Redis...")
            sys.stdout.flush()

            from src.utils.redis_client import get_redis_client
            redis_client = get_redis_client()

            if not redis_client:
                print(">>> [ERROR] Redis å®¢æˆ·ç«¯è¿æ¥å¤±è´¥ï¼ˆè¿”å› Noneï¼‰")
                sys.stdout.flush()
                return False

            print(">>> [DEBUG] Redis è¿æ¥æˆåŠŸï¼Œå‡†å¤‡å†™å…¥å¿ƒè·³æ•°æ®...")
            sys.stdout.flush()

            node_info = {
                'node_id': node_name,
                'node_type': 'worker',
                'workers_per_provider': per_provider,
                'pid': os.getpid(),
                'started_at': started_at,
                'last_heartbeat': datetime.now().isoformat()
            }

            key = f"kg:nodes:{node_name}"
            print(f">>> [DEBUG] å†™å…¥ Redis é”®: {key}")
            print(f">>> [DEBUG] èŠ‚ç‚¹ä¿¡æ¯: {node_info}")
            sys.stdout.flush()

            redis_client.hmset(key, node_info)
            redis_client.expire(key, 180)  # 3åˆ†é’Ÿè¿‡æœŸ

            print(f">>> [DEBUG] Redis å†™å…¥æˆåŠŸï¼é”® {key} å·²è®¾ç½®ï¼Œè¿‡æœŸæ—¶é—´ 180 ç§’")
            sys.stdout.flush()

            logger.debug(f"èŠ‚ç‚¹å¿ƒè·³å·²æ³¨å†Œ: {node_name}")
            return True

        except Exception as e:
            print(f">>> [ERROR] æ³¨å†ŒèŠ‚ç‚¹å¿ƒè·³å¤±è´¥: {e}")
            sys.stdout.flush()
            import traceback
            traceback.print_exc()
            logger.warning(f"æ³¨å†ŒèŠ‚ç‚¹å¿ƒè·³å¤±è´¥: {e}")
            return False

    # é¦–æ¬¡æ³¨å†Œå¿ƒè·³
    heartbeat_success = register_heartbeat()
    if heartbeat_success:
        print(">>> [SUCCESS] âœ“ èŠ‚ç‚¹å¿ƒè·³å·²æˆåŠŸæ³¨å†Œåˆ° Redis")
    else:
        print(">>> [WARNING] âš  èŠ‚ç‚¹å¿ƒè·³æ³¨å†Œå¤±è´¥ï¼ŒWorker å¯åœ¨æœ¬åœ°è¿è¡Œä½†ä¸»èŠ‚ç‚¹æ— æ³•ç›‘æ§")
    sys.stdout.flush()

    # è¾“å‡º Redis è¿æ¥è¯¦æƒ…å’Œç›‘å¬é˜Ÿåˆ—ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ğŸ“¡ è¿æ¥ä¿¡æ¯")
    print("=" * 60)
    redis_host = os.environ.get('REDIS_HOST', 'localhost')
    redis_port = os.environ.get('REDIS_PORT', '6379')
    redis_db = os.environ.get('REDIS_DB', '0')
    print(f"Redis åœ°å€: {redis_host}:{redis_port} (DB: {redis_db})")
    print(f"MySQL åœ°å€: {os.environ.get('DB_HOST', 'N/A')}")
    print(f"Neo4j åœ°å€: {os.environ.get('NEO4J_URI', 'N/A')}")

    # æ˜¾ç¤ºç›‘å¬çš„é˜Ÿåˆ—
    print(f"\nğŸ”Š ç›‘å¬é˜Ÿåˆ—")
    print("=" * 60)
    active_providers = []
    if stats.get('providers'):
        active_providers = list(stats['providers'].keys())

    if active_providers:
        for provider in active_providers:
            queue_key = f"kg:ai_queue:{provider}"
            print(f"  â€¢ Provider: {provider}")
            print(f"    é˜Ÿåˆ—é”®: {queue_key}")
    else:
        print("  âš  æœªå‘ç°æ´»è·ƒçš„ Provider")

    print("=" * 60 + "\n")
    sys.stdout.flush()

    # ä¿æŒä¸»è¿›ç¨‹è¿è¡Œï¼Œå®šæœŸæ›´æ–°å¿ƒè·³
    logger.info("Worker èŠ‚ç‚¹è¿è¡Œä¸­... (æŒ‰ Ctrl+C åœæ­¢)")
    print("ğŸš€ Worker èŠ‚ç‚¹æ­£åœ¨è¿è¡Œ...")
    print("   â€¢ èŠ‚ç‚¹åç§°:", node_name)
    print("   â€¢ ä¸»è¿›ç¨‹ PID:", os.getpid())
    print("   â€¢ æŒ‰ Ctrl+C å¯ä»¥åœæ­¢ Worker\n")
    sys.stdout.flush()

    heartbeat_counter = 0
    try:
        while not _shutdown_requested:
            time.sleep(1)
            heartbeat_counter += 1

            # æ¯60ç§’æ›´æ–°ä¸€æ¬¡å¿ƒè·³
            if heartbeat_counter % 60 == 0:
                register_heartbeat()
                logger.debug(f"[å¿ƒè·³] Worker èŠ‚ç‚¹ [{node_name}] è¿è¡Œæ­£å¸¸")
    except KeyboardInterrupt:
        logger.info("æ”¶åˆ°é”®ç›˜ä¸­æ–­")

    # ä¼˜é›…åœæ­¢
    logger.info("æ­£åœ¨åœæ­¢ Worker èŠ‚ç‚¹...")
    try:
        stop_all_workers(timeout=15)
        logger.info("âœ“ Worker èŠ‚ç‚¹å·²åœæ­¢")
    except Exception as e:
        logger.error(f"âœ— åœæ­¢è¿‡ç¨‹å‡ºé”™: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()
